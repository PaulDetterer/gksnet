{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×800 OneHotMatrix(::Vector{UInt32}) with eltype Bool:\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  …  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  1  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  1  ⋅  1  ⋅  ⋅     1  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  1  ⋅  1\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  …  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅\n",
       " 1  ⋅  ⋅  1  1  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  1  ⋅  ⋅  ⋅  ⋅\n",
       " ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅     ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅  ⋅"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using NPZ\n",
    "using Flux\n",
    "train_ds_x = permutedims(npzread(\"../dataset/TF/train_x.npy\"),[2,3,4,1])\n",
    "# train_ds_orig_x = permutedims(npzread(\"../dataset/TF/train_x.npy\"),[2,3,4,1])\n",
    "train_ds_y = hcat([Flux.onehot(idx,0:7) for idx=npzread(\"../dataset/TF/train_y.npy\")]...)\n",
    "val_ds_x = permutedims(npzread(\"../dataset/TF/val_x.npy\"),[2,3,4,1])\n",
    "val_ds_y = hcat([Flux.onehot(idx,0:7) for idx=npzread(\"../dataset/TF/val_y.npy\")]...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.758846f0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "# Compute mean \n",
    "ds_mean =  mean(train_ds_x)\n",
    "ds_sqrt_var = sqrt(var(train_ds_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLUtils.DataLoader{Tuple{Array{Float32, 4}, Flux.OneHotArray{UInt32, 8, 1, 2, Vector{UInt32}}}, Random._GLOBAL_RNG, Val{nothing}}(([5.0665418f-5 0.000640263 … 0.00015216086 0.00020779307; 0.00065564585 0.00055528636 … 4.3868815f-5 5.2983873f-5; … ; 0.00045395162 0.0009790196 … 3.52279f-5 1.991613f-5; 0.00039587912 0.0006911695 … 0.0001233202 0.00014793497;;;; 5.6987665f-5 0.0012965294 … 6.1849714f-5 4.4529566f-5; 0.00048752356 0.0007681608 … 6.299725f-5 6.3923886f-5; … ; 0.01048574 0.0048514893 … 7.5378244f-5 8.461485f-5; 0.003013047 0.01135004 … 3.9271235f-5 3.2113283f-5;;;; 0.0018243344 0.008706955 … 0.00010042758 3.7692138f-5; 0.0012148265 0.013375979 … 6.976531f-5 2.0443462f-5; … ; 0.0034393203 0.028048309 … 2.7227365f-5 2.537202f-5; 0.0064670327 0.02280002 … 0.00011638377 3.0844007f-5;;;; … ;;;; 0.0021131248 0.0072379573 … 7.941158f-5 2.0045554f-5; 0.0009966363 0.005381674 … 9.4765826f-5 2.001028f-5; … ; 0.00026640831 0.03726436 … 0.00013899719 0.00011997786; 0.016938007 0.030488009 … 0.00010869399 0.00011672638;;;; 0.2480308 0.15608257 … 2.409785f-5 9.803474f-5; 0.2589658 0.14579685 … 8.296626f-5 2.245605f-5; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0;;;; 1.3921657 0.71085757 … 0.0012466881 0.00031012297; 1.1281464 0.6354546 … 0.00031945534 0.0008174181; … ; 2.1327887 1.1554976 … 0.0007055298 0.00046122074; 1.6774678 0.83959615 … 0.00032566648 0.00019109249], Bool[0 0 … 0 0; 0 0 … 0 1; … ; 1 0 … 0 0; 0 0 … 0 0]), 64, false, true, false, false, Val{nothing}(), Random._GLOBAL_RNG())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the DataLoader\n",
    "trainingData = Flux.DataLoader((train_ds_x, train_ds_y), batchsize=64,shuffle=true)\n",
    "valData = Flux.DataLoader((val_ds_x, val_ds_y), batchsize=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8×1 Matrix{Float32}:\n",
       "  0.2695503\n",
       " -0.3293139\n",
       " -0.21712938\n",
       "  0.27615845\n",
       " -0.2459599\n",
       " -0.4050064\n",
       " -0.06462313\n",
       " -0.25922725"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Definition\n",
    "\n",
    "model = Chain(\n",
    "    Upsample(:bilinear,size=(32,32)),\n",
    "    x->(x .- ds_mean) ./ ds_sqrt_var,\n",
    "    Conv((3,3),1=>32, Flux.relu),\n",
    "    Conv((3,3),32=>64, Flux.relu),\n",
    "    MaxPool((2,2)),\n",
    "    Dropout(0.25),\n",
    "    Flux.flatten,\n",
    "    Dense(12544=>128,relu),\n",
    "    Dropout(0.5),\n",
    "    Dense(128=>8),\n",
    ")\n",
    "# Checking \n",
    "model(train_ds_x[:,:,:,1:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss_tot (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loss Function\n",
    "function loss(x,y)\n",
    "    ŷ = model(x)\n",
    "    Flux.Losses.logitcrossentropy(ŷ,y)\n",
    "end\n",
    "\n",
    "# Check Accuracy\n",
    "function getAccuracy(m,d)\n",
    "    acc = 0\n",
    "    for (x,y)=d\n",
    "        ŷ = model(x)\n",
    "        acc += sum(Flux.onecold(ŷ) .== Flux.onecold(y)) / size(x)[end]\n",
    "    end\n",
    "    acc/length(d)\n",
    "end\n",
    "\n",
    "# Total Loss\n",
    "function loss_tot(d)\n",
    "    l = 0\n",
    "    for (x,y) = d\n",
    "        l+= loss(x,y)\n",
    "    end\n",
    "    return l/length(d)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getAccuracy(model, valData) = 0.15144230769230768\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.15144230769230768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Goes very slow :''(\n",
    "#@show loss_tot(valData) \n",
    "testmode!(model,true)\n",
    "@show getAccuracy(model,valData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 1\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.1415434\n",
      "Loss: 1.7251213\n",
      "Loss: 1.5278786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 2\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.409769\n",
      "Loss: 1.2335472\n",
      "Loss: 1.1429584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 3\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1655562\n",
      "Loss: 1.0427951\n",
      "Loss: 1.0319971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 4\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.948192\n",
      "Loss: 0.8971894\n",
      "Loss: 0.87578416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 5\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8769703\n",
      "Loss: 0.79559845\n",
      "Loss: 0.7599188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 6\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8765724\n",
      "Loss: 0.757143\n",
      "Loss: 0.8116492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 7\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.81791294\n",
      "Loss: 0.74064857\n",
      "Loss: 0.7376387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 8\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7227774\n",
      "Loss: 0.76456165\n",
      "Loss: 0.7783826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 9\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7343285\n",
      "Loss: 0.7963575\n",
      "Loss: 0.7309685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Epoch 10\n",
      "└ @ Main C:\\Users\\detter55\\.julia\\packages\\Flux\\js6mP\\src\\optimise\\train.jl:154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.76419026\n",
      "Loss: 0.73187727\n",
      "Loss: 0.63137\n",
      "getAccuracy(model, valData) = 0.8473557692307693\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8473557692307693"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Does not Learn\n",
    "opt = Flux.Optimise.ADAM()\n",
    "ps = Flux.params(model)\n",
    "testmode!(model,false)\n",
    "\n",
    "evalcb() = println(\"Loss: $(loss_tot(valData))\")\n",
    "\n",
    "Flux.@epochs 10 Flux.train!(\n",
    "    loss,\n",
    "    ps,\n",
    "    trainingData,\n",
    "    opt,\n",
    "    cb=Flux.throttle(evalcb,10),\n",
    ")\n",
    "\n",
    "testmode!(model,true)\n",
    "@show getAccuracy(model,valData)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
